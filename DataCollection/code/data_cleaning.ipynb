{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7610241-4666-4ea5-8506-d6cdab451cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('processed_instagram_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "45e35429-558b-4eb1-8cad-33eb5b299678",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning and processing complete. Saved to 'processed_instagram_data.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('minor_college/final_csv.csv')  # Replace with your CSV file\n",
    "\n",
    "# Step 1: Handle Missing Values\n",
    "# Fill missing values in bio and full_name with empty strings\n",
    "df['Bio'] = df['Bio'].fillna('')\n",
    "df['Full Name'] = df['Full Name'].fillna('')\n",
    "df = df.dropna(subset=['Followers', 'Following', 'Username'])  # Drop rows where essential data is missing\n",
    "\n",
    "# Step 2: Remove Outliers using IQR Method\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return df[~((df[column] < (Q1 - 1.5 * IQR)) | (df[column] > (Q3 + 1.5 * IQR)))]\n",
    "\n",
    "df = remove_outliers(df, 'Followers')\n",
    "df = remove_outliers(df, 'Following')\n",
    "\n",
    "# Step 3: Create New Features\n",
    "\n",
    "# (a) Username length\n",
    "df['username_length'] = df['Username'].apply(len)\n",
    "\n",
    "# (b) Number of digits in username\n",
    "df['username_digits'] = df['Username'].apply(lambda x: sum(c.isdigit() for c in x))\n",
    "\n",
    "# (c) Special characters in username\n",
    "df['username_special_chars'] = df['Username'].apply(lambda x: len(re.findall(r'\\W', x)))\n",
    "\n",
    "# (d) Full name vs. username similarity\n",
    "def name_username_similarity(row):\n",
    "    full_name = row['Full Name'].lower().replace(' ', '')\n",
    "    username = row['Username'].lower()\n",
    "    return int(full_name in username)\n",
    "\n",
    "df['name_username_similarity'] = df.apply(name_username_similarity, axis=1)\n",
    "\n",
    "# (e) Bio length\n",
    "df['bio_length'] = df['Bio'].apply(len)\n",
    "\n",
    "# (f) Suspicious keywords in bio\n",
    "suspicious_keywords = [\"money\", \"giveaway\", \"free\", \"bitcoin\", \"forex\", \"investment\"]\n",
    "df['bio_suspicious'] = df['Bio'].apply(lambda bio: 1 if any(word in bio.lower() for word in suspicious_keywords) else 0)\n",
    "\n",
    "# (g) Follower/Following ratio\n",
    "df['follower_following_ratio'] = df['Followers'] / np.where(df['Following'] == 0, 1, df['Following'])\n",
    "\n",
    "# Step 4: Normalize/Standardize numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Select columns to normalize/standardize\n",
    "numerical_features = ['Followers', 'Following', 'username_length', 'bio_length', 'follower_following_ratio', 'Number of Posts']\n",
    "\n",
    "df[numerical_features] = scaler.fit_transform(df[numerical_features])\n",
    "\n",
    "\n",
    "print(\"Data cleaning and processing complete. Saved to 'processed_instagram_data.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b034401-ff51-460e-9918-4dd34f66fa9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60365b3f-9016-490b-bf68-15725e6090e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned data shape: (1021, 11)\n"
     ]
    }
   ],
   "source": [
    "# List of columns to drop because they won't be used for training\n",
    "columns_to_drop = ['Username', 'Full Name', 'Bio','Username Length', 'Username Digits', 'Username Special Chars', 'Full Name Length', 'Username Similarity', 'Full Name Words', 'Has Profile Pic', 'Profile Pic Path', 'Bio Length', 'Bio Words', 'Bio Has Suspicious','External URL', 'Has External URL', 'Is Private']  # Adjust as necessary\n",
    "\n",
    "# Drop the columns\n",
    "df = df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Drop rows where 'followers', 'following', or any other critical feature is missing\n",
    "df = df.dropna(subset=['Followers', 'Following'])\n",
    "\n",
    "# Optionally, reset the index after dropping rows\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(f\"Cleaned data shape: {df.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a493a3df-8f57-466b-9ea1-3dba2aa4a10c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 5: Save the cleaned and processed data\n",
    "df.to_csv('processed_instagram_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03a062a2-491c-4ab0-b1c7-537eae93a7e0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Check for NaN values in the target variable\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43my\u001b[49m\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39msum())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fb088f3-dbf9-44ba-99ff-13559e485ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files merged successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Folder where your CSV files are located\n",
    "folder_path = 'C:/Users/shriv/Downloads/Minor_Project/DataCollection/data'\n",
    "\n",
    "# List to hold all dataframes\n",
    "dataframes = []\n",
    "\n",
    "# Loop through all files in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Read the CSV file into a dataframe\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "# Concatenate all dataframes into a single dataframe\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_df.to_csv('mergedtext_file.csv', index=False)\n",
    "\n",
    "print(\"CSV files merged successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb589a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
